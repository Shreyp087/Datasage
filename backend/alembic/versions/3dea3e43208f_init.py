"""Init

Revision ID: 3dea3e43208f
Revises: 
Create Date: 2026-02-27 17:21:17.463962

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '3dea3e43208f'
down_revision: Union[str, None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None

def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('users',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('email', sa.String(), nullable=False),
    sa.Column('hashed_password', sa.String(), nullable=False),
    sa.Column('name', sa.String(), nullable=False),
    sa.Column('plan', sa.Enum('free', 'pro', 'enterprise', name='planenum'), nullable=False),
    sa.Column('storage_used_bytes', sa.BigInteger(), nullable=False),
    sa.Column('created_at', sa.DateTime(timezone=True), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), nullable=False),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_users_email'), 'users', ['email'], unique=True)
    op.create_table('datasets',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('user_id', sa.UUID(), nullable=False),
    sa.Column('name', sa.String(), nullable=False),
    sa.Column('description', sa.Text(), nullable=True),
    sa.Column('domain', sa.Enum('general', 'healthcare', 'finance', 'education', 'ecommerce', 'other', name='datasetdomainenum'), nullable=False),
    sa.Column('original_filename', sa.String(), nullable=False),
    sa.Column('storage_path', sa.String(), nullable=True),
    sa.Column('cleaned_storage_path', sa.String(), nullable=True),
    sa.Column('file_format', sa.Enum('csv', 'excel', 'json', 'parquet', 'tsv', 'zip', name='fileformatenum'), nullable=False),
    sa.Column('row_count', sa.BigInteger(), nullable=True),
    sa.Column('col_count', sa.Integer(), nullable=True),
    sa.Column('file_size_bytes', sa.BigInteger(), nullable=False),
    sa.Column('status', sa.Enum('uploaded', 'queued', 'preprocessing', 'eda_running', 'agents_running', 'complete', 'failed', name='datasetstatusenum'), nullable=False),
    sa.Column('schema_json', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('uploaded_at', sa.DateTime(timezone=True), nullable=False),
    sa.Column('completed_at', sa.DateTime(timezone=True), nullable=True),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_datasets_status'), 'datasets', ['status'], unique=False)
    op.create_index(op.f('ix_datasets_user_id'), 'datasets', ['user_id'], unique=False)
    op.create_table('agent_reports',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('dataset_id', sa.UUID(), nullable=False),
    sa.Column('agent_name', sa.String(), nullable=False),
    sa.Column('agent_role', sa.String(), nullable=False),
    sa.Column('report_markdown', sa.Text(), nullable=True),
    sa.Column('structured_json', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('tokens_used', sa.Integer(), nullable=False),
    sa.Column('model_used', sa.String(), nullable=False),
    sa.Column('created_at', sa.DateTime(timezone=True), nullable=False),
    sa.ForeignKeyConstraint(['dataset_id'], ['datasets.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_agent_reports_dataset_id'), 'agent_reports', ['dataset_id'], unique=False)
    op.create_table('dataset_groups',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('user_id', sa.UUID(), nullable=False),
    sa.Column('name', sa.String(), nullable=False),
    sa.Column('dataset_ids', sa.ARRAY(sa.UUID()), nullable=False),
    sa.Column('result_dataset_id', sa.UUID(), nullable=True),
    sa.ForeignKeyConstraint(['result_dataset_id'], ['datasets.id'], ),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_dataset_groups_user_id'), 'dataset_groups', ['user_id'], unique=False)
    op.create_table('eda_reports',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('dataset_id', sa.UUID(), nullable=False),
    sa.Column('html_report_path', sa.String(), nullable=True),
    sa.Column('json_summary', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('profile_stats', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), nullable=False),
    sa.ForeignKeyConstraint(['dataset_id'], ['datasets.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_eda_reports_dataset_id'), 'eda_reports', ['dataset_id'], unique=False)
    op.create_table('merge_configs',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('user_id', sa.UUID(), nullable=False),
    sa.Column('left_dataset_id', sa.UUID(), nullable=False),
    sa.Column('right_dataset_id', sa.UUID(), nullable=False),
    sa.Column('left_key', sa.String(), nullable=False),
    sa.Column('right_key', sa.String(), nullable=False),
    sa.Column('join_type', sa.Enum('inner', 'left', 'right', 'outer', name='jointypeenum'), nullable=False),
    sa.Column('result_dataset_id', sa.UUID(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), nullable=False),
    sa.ForeignKeyConstraint(['left_dataset_id'], ['datasets.id'], ),
    sa.ForeignKeyConstraint(['result_dataset_id'], ['datasets.id'], ),
    sa.ForeignKeyConstraint(['right_dataset_id'], ['datasets.id'], ),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_merge_configs_user_id'), 'merge_configs', ['user_id'], unique=False)
    op.create_table('processing_jobs',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('dataset_id', sa.UUID(), nullable=False),
    sa.Column('status', sa.Enum('uploaded', 'queued', 'preprocessing', 'eda_running', 'agents_running', 'complete', 'failed', name='datasetstatusenum'), nullable=False),
    sa.Column('progress_pct', sa.Float(), nullable=False),
    sa.Column('current_step', sa.String(), nullable=True),
    sa.Column('error_message', sa.Text(), nullable=True),
    sa.Column('traceback', sa.Text(), nullable=True),
    sa.Column('started_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('completed_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), nullable=False),
    sa.ForeignKeyConstraint(['dataset_id'], ['datasets.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_processing_jobs_dataset_id'), 'processing_jobs', ['dataset_id'], unique=False)
    op.create_index(op.f('ix_processing_jobs_status'), 'processing_jobs', ['status'], unique=False)
    op.create_table('processing_logs',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('job_id', sa.UUID(), nullable=False),
    sa.Column('step_name', sa.String(), nullable=False),
    sa.Column('action', sa.String(), nullable=False),
    sa.Column('column_name', sa.String(), nullable=True),
    sa.Column('before_value', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('after_value', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('reason', sa.String(), nullable=True),
    sa.Column('severity', sa.Enum('info', 'warning', 'error', name='severityenum'), nullable=False),
    sa.Column('created_at', sa.DateTime(timezone=True), nullable=False),
    sa.ForeignKeyConstraint(['job_id'], ['processing_jobs.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_processing_logs_job_id'), 'processing_logs', ['job_id'], unique=False)
    # ### end Alembic commands ###

def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_processing_logs_job_id'), table_name='processing_logs')
    op.drop_table('processing_logs')
    op.drop_index(op.f('ix_processing_jobs_status'), table_name='processing_jobs')
    op.drop_index(op.f('ix_processing_jobs_dataset_id'), table_name='processing_jobs')
    op.drop_table('processing_jobs')
    op.drop_index(op.f('ix_merge_configs_user_id'), table_name='merge_configs')
    op.drop_table('merge_configs')
    op.drop_index(op.f('ix_eda_reports_dataset_id'), table_name='eda_reports')
    op.drop_table('eda_reports')
    op.drop_index(op.f('ix_dataset_groups_user_id'), table_name='dataset_groups')
    op.drop_table('dataset_groups')
    op.drop_index(op.f('ix_agent_reports_dataset_id'), table_name='agent_reports')
    op.drop_table('agent_reports')
    op.drop_index(op.f('ix_datasets_user_id'), table_name='datasets')
    op.drop_index(op.f('ix_datasets_status'), table_name='datasets')
    op.drop_table('datasets')
    op.drop_index(op.f('ix_users_email'), table_name='users')
    op.drop_table('users')
    # ### end Alembic commands ###
